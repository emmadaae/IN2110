{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IN2110 Våren 2021 - Obligatorisk innlevering 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 1: Logistisk Regresjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Forberedelser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I den første delene av av denne innleveringen, bruker vi logistisk regresjon for å utvikle en enkel språkidentifikator.\n",
    "For å trene denne modellen, skal vi ta i bruk allerede eksisterende lister over ord med deres fonetiske transkripsjoner i såkalt IPA-format.\n",
    "Vi starter da med å importere filen \"logistisk_regresjon.py\" og laste ned dataene som skal brukes videre i oppgaven..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nedlasting av ordisten for norsk... ferdig!\n",
      "Nedlasting av ordisten for arabisk... ferdig!\n",
      "Nedlasting av ordisten for finsk... ferdig!\n",
      "Nedlasting av ordisten for patwa... ferdig!\n",
      "Nedlasting av ordisten for farsi... ferdig!\n",
      "Nedlasting av ordisten for tysk... ferdig!\n",
      "Nedlasting av ordisten for engelsk... ferdig!\n",
      "Nedlasting av ordisten for rumensk... ferdig!\n",
      "Nedlasting av ordisten for khmer... ferdig!\n",
      "Nedlasting av ordisten for fransk... ferdig!\n",
      "Nedlasting av ordisten for japansk... ferdig!\n",
      "Nedlasting av ordisten for spansk... ferdig!\n",
      "Nedlasting av ordisten for svensk... ferdig!\n",
      "Nedlasting av ordisten for koreansk... ferdig!\n",
      "Nedlasting av ordisten for swahilisk... ferdig!\n",
      "Nedlasting av ordisten for vietnamesisk... ferdig!\n",
      "Nedlasting av ordisten for mandarin... ferdig!\n",
      "Nedlasting av ordisten for malayisk... ferdig!\n",
      "Nedlasting av ordisten for kantonesisk... ferdig!\n",
      "Nedlasting av ordisten for islandsk... ferdig!\n",
      "Treningsett: 309074 eksempler, testsett: 34342 eksempler\n"
     ]
    }
   ],
   "source": [
    "import logistisk_regresjon as lr\n",
    "train, test = lr.extract_wordlist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det \"extract_wordlist()\" metoden gjør er at den laster ned en rekke filer fra GitHub og samler innholdet av disse i to \"DataFrame\" objekter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ord</th>\n",
       "      <th>IPA</th>\n",
       "      <th>språk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86692</th>\n",
       "      <td>neutrality</td>\n",
       "      <td>njuːtɹˈælɪti</td>\n",
       "      <td>engelsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78777</th>\n",
       "      <td>vaterlose</td>\n",
       "      <td>ˈvɑːtɐ̯ˌloːze</td>\n",
       "      <td>tysk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11238</th>\n",
       "      <td>فيتفوق</td>\n",
       "      <td>feɪatafawwaq</td>\n",
       "      <td>arabisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93566</th>\n",
       "      <td>listed</td>\n",
       "      <td>lˈɪstɪd</td>\n",
       "      <td>engelsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141232</th>\n",
       "      <td>dépannerais</td>\n",
       "      <td>depanəʁɛ</td>\n",
       "      <td>fransk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200095</th>\n",
       "      <td>studium</td>\n",
       "      <td>stˈʉːdɪɵm</td>\n",
       "      <td>svensk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215447</th>\n",
       "      <td>광고지</td>\n",
       "      <td>kwa̠ŋɡo̞d͡ʑi</td>\n",
       "      <td>koreansk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116315</th>\n",
       "      <td>venezuelit</td>\n",
       "      <td>venezuelit</td>\n",
       "      <td>rumensk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295670</th>\n",
       "      <td>nazar</td>\n",
       "      <td>nazar</td>\n",
       "      <td>malayisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221034</th>\n",
       "      <td>같음</td>\n",
       "      <td>ka̠tʰɯm</td>\n",
       "      <td>koreansk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248402</th>\n",
       "      <td>khôn sống mống chết</td>\n",
       "      <td>xoŋ͡m˧˥ ʂoŋ͡m˩˧ moŋ͡m˩˧ cet˦˥</td>\n",
       "      <td>vietnamesisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91854</th>\n",
       "      <td>hypothermia</td>\n",
       "      <td>hˌa‍ɪpə‍ʊθˈɜːmiɐ</td>\n",
       "      <td>engelsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93498</th>\n",
       "      <td>quantum</td>\n",
       "      <td>kwˈɒntəm</td>\n",
       "      <td>engelsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243057</th>\n",
       "      <td>vikongwe</td>\n",
       "      <td>vikoᵑgwe</td>\n",
       "      <td>swahilisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93032</th>\n",
       "      <td>borrowing</td>\n",
       "      <td>bˈɒɹə‍ʊɪŋ</td>\n",
       "      <td>engelsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224333</th>\n",
       "      <td>kitafidiwa</td>\n",
       "      <td>kitafiɗiwa</td>\n",
       "      <td>swahilisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324375</th>\n",
       "      <td>samheldni</td>\n",
       "      <td>saːmhɛltnɪ</td>\n",
       "      <td>islandsk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293586</th>\n",
       "      <td>atung</td>\n",
       "      <td>atuŋ</td>\n",
       "      <td>malayisk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132322</th>\n",
       "      <td>transplantai</td>\n",
       "      <td>tʁɑ̃splɑ̃tɛ</td>\n",
       "      <td>fransk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183860</th>\n",
       "      <td>bryggare</td>\n",
       "      <td>²brˈʏgːarɛ</td>\n",
       "      <td>svensk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ord                            IPA         språk\n",
       "86692            neutrality                   njuːtɹˈælɪti       engelsk\n",
       "78777             vaterlose                  ˈvɑːtɐ̯ˌloːze          tysk\n",
       "11238                فيتفوق                   feɪatafawwaq       arabisk\n",
       "93566                listed                        lˈɪstɪd       engelsk\n",
       "141232          dépannerais                       depanəʁɛ        fransk\n",
       "200095              studium                      stˈʉːdɪɵm        svensk\n",
       "215447                  광고지                   kwa̠ŋɡo̞d͡ʑi      koreansk\n",
       "116315           venezuelit                     venezuelit       rumensk\n",
       "295670                nazar                          nazar      malayisk\n",
       "221034                   같음                        ka̠tʰɯm      koreansk\n",
       "248402  khôn sống mống chết  xoŋ͡m˧˥ ʂoŋ͡m˩˧ moŋ͡m˩˧ cet˦˥  vietnamesisk\n",
       "91854           hypothermia               hˌa‍ɪpə‍ʊθˈɜːmiɐ       engelsk\n",
       "93498               quantum                       kwˈɒntəm       engelsk\n",
       "243057             vikongwe                       vikoᵑgwe     swahilisk\n",
       "93032             borrowing                      bˈɒɹə‍ʊɪŋ       engelsk\n",
       "224333           kitafidiwa                     kitafiɗiwa     swahilisk\n",
       "324375            samheldni                     saːmhɛltnɪ      islandsk\n",
       "293586                atung                           atuŋ      malayisk\n",
       "132322         transplantai                    tʁɑ̃splɑ̃tɛ        fransk\n",
       "183860             bryggare                     ²brˈʏgːarɛ        svensk"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Trening av modellen                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I denne delen av oppgaven skal vi trene modellen vår. Vi benytter oss av en logistisk regresjonsmodell. For dette bruker vi:\n",
    "- \"LogisticRegression\" (fra scikit-learn)\n",
    "\n",
    "Trekkene (features) som brukes i denne modellen er de så kalte \"IPA\"-symboler, som identifiserer ordlyder, i den fonetiske transkripsjonen av ordet. Sist, men ikke minst, vil disse trekkene (features) ha binære verdier (1 og 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lr.LanguageIdentifier()\n",
    "transcriptions = train.IPA.values\n",
    "languages = train.språk.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Det første skrittet for å kunne løse oppgaven er at vi lager en liste over alle IPA-symboler som finnes i treningsettet. Vi da tar inn alle de fonetiske transkripsjonene fra treningssettet som input i følgende metode, og \n",
    "returnerer en liste med alle de fonetiske symboler, altså tegn, som finnes i nettop disse transkripsjoner som vi sendte inn. \n",
    "\n",
    "Vi har merket at antall symboler vil variere avhengig av den tilfeldig inndelingen mellom treningssettet og testsettet. Noen ganger får vi 154 og noen ganger får vi 156, men disse ligger da rundt 155 unike symboler.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x._extract_unique_symbols(transcriptions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Det vi skal gjøre videre er å implementere _extract_features(transcriptions)-metoden som vil da ta samme liste som i forrige metode, altså \"transcriptions\", og returnere en matrise X hvor hver rad tilsvarer en transkripsjon og \n",
    "hver kolonne representerer en bestemt trekk. \n",
    "\n",
    "Vi starter med å lage en tom matrise slik som X = np.zeros(n, m) og deretter endre cellene hvor X [i, j] skal ha 1 som verdi dersom symbolet forekommer i transkripsjonen, i stedet for å ha verdien 0. Til slutt, etter at vi implementerer det nødvendig algoritme, returnerer vi matrisen X av dimensjonen (n, m).\n",
    "\n",
    "    m -> unike fonetiske symboler                  n -> fonetiske transkripsjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x._extract_feats(transcriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Nå som vi har implementert 2 grunnlegende metoder for vårt oblig, er vi nå klare for å implementere train(transcriptions, languages). Metoden tar to lister som input, en liste fonetiske transkripsjoner og en liste med språknavn (de to listene må selvsagt ha samme lengde for å kunne kjøre programmet riktig). \n",
    "\n",
    "Denne metoden vil da trene den \"logistiske regresjonsmodellen\" (self.model) ved å kalle på fit-metoden. En ting å merke seg er at scikit-learn krever at outputklassen \"languages\" må være en liste med heltall, og ikke med strenger. Vi må da lage en slags \"mapping\" mellom språknavn og heltall . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Prediksjon og evaluering med modellen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mest sansynnlige språk for ordene: ['spansk', 'norsk', 'islandsk', 'tysk']\n"
     ]
    }
   ],
   "source": [
    "x.sprak(languages)\n",
    "x.train(transcriptions, languages)\n",
    "predicted_langs = x.predict([\"konstituˈθjon\", \"ɡrʉnlɔʋ\", \"stjourtnar̥skrauːɪn\", \"bʊndɛsvɛɾfaszʊŋ\"])\n",
    "print(\"Mest sansynnlige språk for ordene:\", predicted_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Til slutt kan vi gjennomføre en grundigere evaluering av modellen basert på testsettet. \n",
    "Inplementer metoden evaluete(transcriptions, languages). Metoden skal da beregne og skrive \n",
    "ut de følgende evalueringsmålene:\n",
    "- accuracy \n",
    "- precision, recall og F1 for hvert sprak. \n",
    "- micro-og macro-averaged F1. \n",
    "For å beregne disse tallene kan vi bruke metodene fra sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Accuracy: 0.9275813872226428 -\n",
      "\n",
      "\n",
      "- precision, recall og F1 for hvert språk - \n",
      "\n",
      "                 precision    recall     F1-(micro)  \n",
      "norsk              0.828       0.880       0.853\n",
      "arabisk            0.940       0.964       0.951\n",
      "finsk              0.996       0.988       0.992\n",
      "patwa              0.433       0.910       0.587\n",
      "farsi              0.959       0.948       0.954\n",
      "tysk               0.929       0.955       0.942\n",
      "engelsk            0.964       0.965       0.965\n",
      "rumensk            0.803       0.764       0.783\n",
      "khmer              0.675       0.933       0.783\n",
      "fransk             0.913       0.955       0.934\n",
      "japansk            0.943       0.983       0.962\n",
      "spansk             0.915       0.934       0.924\n",
      "svensk             0.952       0.956       0.954\n",
      "koreansk           0.996       1.000       0.998\n",
      "swahilisk          0.923       0.811       0.863\n",
      "vietnamesisk       0.975       0.973       0.974\n",
      "mandarin           0.976       0.948       0.962\n",
      "malayisk           0.835       0.757       0.794\n",
      "kantonesisk        0.963       0.996       0.979\n",
      "islandsk           0.934       0.948       0.941\n",
      "\n",
      "- macro (f1-score) -\n",
      "f1-score: 0.9048195077188353\n"
     ]
    }
   ],
   "source": [
    "transcriptions_test = test.IPA.values\n",
    "languages_test = test.språk.values\n",
    "x.evaluate(transcriptions_test, languages_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etter å ha kjørt denne delen av koden, får vi en accuracy på 0.927, det vil si en accuracy på 93%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Prediksjon og evaluering med modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Del 2: Sekvensmodeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I denne delen av obligen, skal vi jobbe med en viktig anvendelse av sekvensmodeller, nemlig det å gjenkjenne\n",
    "navngitte entiter (Named Entity Recognition). Denne gangen skal vi ta i bruk det så-kalte \"Hidden Markov Model\". \n",
    "Hvert ord skal assosieres med en bestemt klasse og vi skal ta i bruk BIO-annotering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ner as n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.testing()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
